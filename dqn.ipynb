{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from environment import EnvironmentGoogleSnake\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreProcessEnv(gym.Wrapper):\n",
    "\n",
    "    def __init__(self, env):\n",
    "        gym.Wrapper.__init__(self, env=env)\n",
    "\n",
    "    def reset(self):\n",
    "        obs = self.env.reset()\n",
    "        return ToTensor()(obs).unsqueeze(dim = 0).float()\n",
    "    \n",
    "    def step(self, action: torch.Tensor):\n",
    "        action = action.item()\n",
    "        next_state, reward, done, info = self.env.step(action)\n",
    "        next_state = ToTensor()(next_state).unsqueeze(dim = 0)\n",
    "        reward = torch.tensor(reward).view(1, -1).float()\n",
    "        done = torch.tensor(done).view(1, -1)\n",
    "        return next_state, reward, done, info\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = EnvironmentGoogleSnake()\n",
    "env = PreProcessEnv(env)\n",
    "\n",
    "env.unwrapped.start()\n",
    "state = env.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 127.5, 127.5, -0.5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "next_state, reward, done, info = env.step(torch.tensor(2))\n",
    "\n",
    "plt.imshow(next_state.squeeze(), cmap=\"gray\")\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepRLModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, hidden_units, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv_block_1 = torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(in_channels = in_channels, out_channels = hidden_units, kernel_size = 3, padding = 1),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Conv2d(in_channels=hidden_units, out_channels = hidden_units, kernel_size = 3, padding = 1),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        )\n",
    "\n",
    "        self.conv_block_2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels = hidden_units, out_channels = hidden_units, kernel_size =3, padding = 1 ),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(in_channels = hidden_units, out_channels = hidden_units, kernel_size = 3, padding = 1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.classifier = torch.nn.Sequential(\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(in_features = 20480, out_features = out_channels),\n",
    "            torch.nn.Softmax(dim = 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.classifier(self.conv_block_2(self.conv_block_1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "DeepRLModel                              [3, 4]                    --\n",
       "├─Sequential: 1-1                        [3, 20, 64, 64]           --\n",
       "│    └─Conv2d: 2-1                       [3, 20, 128, 128]         200\n",
       "│    └─ReLU: 2-2                         [3, 20, 128, 128]         --\n",
       "│    └─Conv2d: 2-3                       [3, 20, 128, 128]         3,620\n",
       "│    └─ReLU: 2-4                         [3, 20, 128, 128]         --\n",
       "│    └─MaxPool2d: 2-5                    [3, 20, 64, 64]           --\n",
       "├─Sequential: 1-2                        [3, 20, 32, 32]           --\n",
       "│    └─Conv2d: 2-6                       [3, 20, 64, 64]           3,620\n",
       "│    └─ReLU: 2-7                         [3, 20, 64, 64]           --\n",
       "│    └─Conv2d: 2-8                       [3, 20, 64, 64]           3,620\n",
       "│    └─ReLU: 2-9                         [3, 20, 64, 64]           --\n",
       "│    └─MaxPool2d: 2-10                   [3, 20, 32, 32]           --\n",
       "├─Sequential: 1-3                        [3, 4]                    --\n",
       "│    └─Flatten: 2-11                     [3, 20480]                --\n",
       "│    └─Linear: 2-12                      [3, 4]                    81,924\n",
       "│    └─Softmax: 2-13                     [3, 4]                    --\n",
       "==========================================================================================\n",
       "Total params: 92,984\n",
       "Trainable params: 92,984\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 276.97\n",
       "==========================================================================================\n",
       "Input size (MB): 0.20\n",
       "Forward/backward pass size (MB): 19.66\n",
       "Params size (MB): 0.37\n",
       "Estimated Total Size (MB): 20.23\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "q_network = DeepRLModel(1, 20, 4).to(device)\n",
    "summary(q_network, (3, 1,  128, 128))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_q_network = copy.deepcopy(q_network).to(device).eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2437]], device='cuda:0', grad_fn=<GatherBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_network(next_state.to(device)).gather(1, torch.tensor([[1]]).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy(state, epsilon = 0.05):\n",
    "    if torch.rand(1) < epsilon:\n",
    "        return torch.randint(4, (1, 1))\n",
    "    else:\n",
    "        av = q_network(state.to(device))\n",
    "        return torch.argmax(av, dim = -1, keepdim = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from memory import ReplayMemory\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def dqn_training(\n",
    "    q_network: DeepRLModel,\n",
    "    policy,\n",
    "    episodes,\n",
    "    alpha=0.0001,\n",
    "    batch_size=32,\n",
    "    gamma=0.99,\n",
    "    epsilon=0.05,\n",
    "):\n",
    "    optim = torch.optim.AdamW(q_network.parameters(), lr=alpha)\n",
    "    memory = ReplayMemory(capacity=10000)\n",
    "    stats = {'MSE Loss': [], 'Returns': []}\n",
    "    \n",
    "    for episode in tqdm(range(1, episodes + 1)):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        ep_return = 0\n",
    "        while not done:\n",
    "            action = policy(state, epsilon)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "            done = done.to(device)\n",
    "            next_state = next_state.to(device)\n",
    "            state = state.to(device)\n",
    "            action = action.to(device)\n",
    "            reward = reward.to(device)\n",
    "            \n",
    "            memory.insert([state, action, reward, done, next_state])\n",
    "            \n",
    "            if memory.can_sample(batch_size):\n",
    "                state_b, action_b, reward_b, done_b, next_state_b = memory.sample(batch_size)   \n",
    "\n",
    "                reward_b = reward_b.to(device)\n",
    "                done_b = done_b.to(device)\n",
    "                state_b = state_b.to(device)\n",
    "                action_b = action_b.to(device)\n",
    "\n",
    "\n",
    "                qsa_b = q_network(state_b).gather(1, action_b)\n",
    "                \n",
    "                next_qsa_b = target_q_network(next_state_b.to(device))\n",
    "                next_qsa_b = torch.max(next_qsa_b, dim=-1, keepdim=True)[0].to(device)\n",
    "                \n",
    "                target_b = reward_b + ~(done) * gamma * next_qsa_b\n",
    "                loss = F.mse_loss(qsa_b, target_b.to(device))\n",
    "                q_network.zero_grad()\n",
    "                loss.backward()\n",
    "                optim.step()\n",
    "                \n",
    "                stats['MSE Loss'].append(loss)  \n",
    "                \n",
    "            state = next_state\n",
    "            ep_return += reward.item()\n",
    "            \n",
    "        \n",
    "        stats['Returns'].append(ep_return)\n",
    "        \n",
    "        if episode % 10 == 0:\n",
    "            target_q_network.load_state_dict(q_network.state_dict())\n",
    "\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 54/1000 [03:09<53:34,  3.40s/it]  "
     ]
    }
   ],
   "source": [
    "dqn_training(q_network, policy, episodes = 1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autodrive-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
